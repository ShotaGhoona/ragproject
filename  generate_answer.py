import os
import pickle
import faiss
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# æ¤œç´¢ç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
text_chunks = pickle.load(open("sentences.pkl", "rb"))  # [(filename, sentence)]
index = faiss.read_index("faiss_index.bin")
model = SentenceTransformer("all-MiniLM-L6-v2")

# è³ªå•
question = input("ğŸ’¬ è³ªå•ã‚’ã©ã†ãï¼š")
query_embedding = model.encode([question])
D, I = index.search(query_embedding, k=3)

# é–¢é€£æ–‡ã‚’æ•´å½¢
relevant = [text_chunks[idx] for idx in I[0]]
context = "\n".join([f"[{filename}] {sentence}" for filename, sentence in relevant])

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
prompt = f"""ä»¥ä¸‹ã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

### å‚è€ƒæƒ…å ±:
{context}

### è³ªå•:
{question}

### å›ç­”:"""

# LLMã«å•ã„åˆã‚ã›
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": prompt}],
)

# å›ç­”è¡¨ç¤º
answer = response.choices[0].message.content
print("\nğŸ§  å›ç­”:")
print(answer)
