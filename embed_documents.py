import os
from pathlib import Path
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
import faiss
import pickle
from glob import glob

load_dotenv()
docs_dir = Path("docs")
model = SentenceTransformer("all-MiniLM-L6-v2")

text_chunks = []

# ğŸ” å…¨ .txt ã‚’å‡¦ç†
for filepath in glob(str(docs_dir / "*.txt")):
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()
        filename = Path(filepath).name
        sentences = [s.strip() for s in content.split("ã€‚") if s.strip()]
        for sentence in sentences:
            text_chunks.append((filename, sentence))

# ãƒ™ã‚¯ãƒˆãƒ«åŒ–
sentences_only = [s for (_, s) in text_chunks]
embeddings = model.encode(sentences_only)

# ä¿å­˜
with open("sentences.pkl", "wb") as f:
    pickle.dump(text_chunks, f)

dim = embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(embeddings)
faiss.write_index(index, "faiss_index.bin")

print("âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
